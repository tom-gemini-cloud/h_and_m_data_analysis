{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# BERT Embeddings Clustering Analysis\n",
    "\n",
    "This notebook performs clustering analysis on H&M product articles using pre-computed BERT embeddings.\n",
    "The BERT embeddings capture semantic information from product descriptions, enabling meaningful product groupings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')\n",
    "\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "try:\n",
    "    import umap\n",
    "    UMAP_AVAILABLE = True\n",
    "except ImportError:\n",
    "    UMAP_AVAILABLE = False\n",
    "    print(\"UMAP not available. Install with: pip install umap-learn\")\n",
    "\n",
    "try:\n",
    "    import hdbscan\n",
    "    HDBSCAN_AVAILABLE = True\n",
    "except ImportError:\n",
    "    HDBSCAN_AVAILABLE = False\n",
    "    print(\"HDBSCAN not available. Install with: pip install hdbscan\")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Exploration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load BERT embeddings\n",
    "print(\"Loading BERT embeddings...\")\n",
    "bert_df = pl.read_parquet('../../data/features/bert/bert_embeddings.parquet')\n",
    "\n",
    "print(f\"Dataset shape: {bert_df.shape}\")\n",
    "print(f\"Memory usage: {bert_df.estimated_size() / 1024**2:.1f} MB\")\n",
    "print(f\"Columns: {len(bert_df.columns)} (article_id + {len(bert_df.columns)-1} BERT features)\")\n",
    "\n",
    "# Display basic statistics\n",
    "bert_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract embeddings matrix and article IDs\n",
    "article_ids = bert_df.get_column('article_id').to_numpy()\n",
    "embedding_cols = [col for col in bert_df.columns if col.startswith('bert_')]\n",
    "embeddings = bert_df.select(embedding_cols).to_numpy()\n",
    "\n",
    "print(f\"Embeddings shape: {embeddings.shape}\")\n",
    "print(f\"Embedding dimensions: {len(embedding_cols)}\")\n",
    "print(f\"Data type: {embeddings.dtype}\")\n",
    "\n",
    "# Check for missing values\n",
    "missing_count = np.isnan(embeddings).sum()\n",
    "print(f\"Missing values: {missing_count}\")\n",
    "\n",
    "# Basic statistics\n",
    "print(f\"\\nEmbedding statistics:\")\n",
    "print(f\"Mean: {embeddings.mean():.4f}\")\n",
    "print(f\"Std: {embeddings.std():.4f}\")\n",
    "print(f\"Min: {embeddings.min():.4f}\")\n",
    "print(f\"Max: {embeddings.max():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## 2. Dimensionality Reduction for Visualisation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA for initial dimensionality reduction\n",
    "print(\"Performing PCA...\")\n",
    "pca = PCA(n_components=50, random_state=42)\n",
    "embeddings_pca = pca.fit_transform(embeddings)\n",
    "\n",
    "print(f\"PCA explained variance ratio: {pca.explained_variance_ratio_[:10]}\")\n",
    "print(f\"Cumulative explained variance (50 components): {pca.explained_variance_ratio_.sum():.3f}\")\n",
    "\n",
    "# Plot explained variance\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, 21), pca.explained_variance_ratio_[:20], 'bo-')\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('Explained Variance Ratio')\n",
    "plt.title('PCA Explained Variance (First 20 Components)')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, 51), np.cumsum(pca.explained_variance_ratio_), 'ro-')\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.title('Cumulative Explained Variance')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-SNE for 2D visualisation (using PCA-reduced data for speed)\n",
    "print(\"Performing t-SNE...\")\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=30, n_iter=1000)\n",
    "embeddings_tsne = tsne.fit_transform(embeddings_pca)\n",
    "\n",
    "print(f\"t-SNE shape: {embeddings_tsne.shape}\")\n",
    "\n",
    "# Plot t-SNE\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(embeddings_tsne[:, 0], embeddings_tsne[:, 1], alpha=0.6, s=1)\n",
    "plt.xlabel('t-SNE 1')\n",
    "plt.ylabel('t-SNE 2')\n",
    "plt.title('t-SNE Visualisation of BERT Embeddings')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UMAP if available\n",
    "if UMAP_AVAILABLE:\n",
    "    print(\"Performing UMAP...\")\n",
    "    umap_reducer = umap.UMAP(n_components=2, random_state=42, n_neighbors=15, min_dist=0.1)\n",
    "    embeddings_umap = umap_reducer.fit_transform(embeddings_pca)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.scatter(embeddings_umap[:, 0], embeddings_umap[:, 1], alpha=0.6, s=1)\n",
    "    plt.xlabel('UMAP 1')\n",
    "    plt.ylabel('UMAP 2')\n",
    "    plt.title('UMAP Visualisation of BERT Embeddings')\n",
    "    plt.show()\n",
    "else:\n",
    "    embeddings_umap = None\n",
    "    print(\"Skipping UMAP - not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## 3. K-means Clustering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine optimal number of clusters using elbow method\n",
    "print(\"Finding optimal number of clusters...\")\n",
    "k_range = range(2, 50)\n",
    "inertias = []\n",
    "silhouette_scores = []\n",
    "calinski_scores = []\n",
    "davies_bouldin_scores = []\n",
    "\n",
    "# Use PCA-reduced data for faster computation\n",
    "X_clustering = embeddings_pca\n",
    "\n",
    "for k in k_range:\n",
    "    print(f\"Testing k={k}...\")\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    labels = kmeans.fit_predict(X_clustering)\n",
    "    \n",
    "    inertias.append(kmeans.inertia_)\n",
    "    silhouette_scores.append(silhouette_score(X_clustering, labels))\n",
    "    calinski_scores.append(calinski_harabasz_score(X_clustering, labels))\n",
    "    davies_bouldin_scores.append(davies_bouldin_score(X_clustering, labels))\n",
    "\n",
    "# Plot clustering metrics\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "axes[0, 0].plot(k_range, inertias, 'bo-')\n",
    "axes[0, 0].set_xlabel('Number of Clusters (k)')\n",
    "axes[0, 0].set_ylabel('Inertia')\n",
    "axes[0, 0].set_title('Elbow Method')\n",
    "axes[0, 0].grid(True)\n",
    "\n",
    "axes[0, 1].plot(k_range, silhouette_scores, 'ro-')\n",
    "axes[0, 1].set_xlabel('Number of Clusters (k)')\n",
    "axes[0, 1].set_ylabel('Silhouette Score')\n",
    "axes[0, 1].set_title('Silhouette Score')\n",
    "axes[0, 1].grid(True)\n",
    "\n",
    "axes[1, 0].plot(k_range, calinski_scores, 'go-')\n",
    "axes[1, 0].set_xlabel('Number of Clusters (k)')\n",
    "axes[1, 0].set_ylabel('Calinski-Harabasz Score')\n",
    "axes[1, 0].set_title('Calinski-Harabasz Score')\n",
    "axes[1, 0].grid(True)\n",
    "\n",
    "axes[1, 1].plot(k_range, davies_bouldin_scores, 'mo-')\n",
    "axes[1, 1].set_xlabel('Number of Clusters (k)')\n",
    "axes[1, 1].set_ylabel('Davies-Bouldin Score')\n",
    "axes[1, 1].set_title('Davies-Bouldin Score (Lower is Better)')\n",
    "axes[1, 1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Find optimal k based on silhouette score\n",
    "optimal_k = k_range[np.argmax(silhouette_scores)]\n",
    "print(f\"\\nOptimal k based on silhouette score: {optimal_k}\")\n",
    "print(f\"Best silhouette score: {max(silhouette_scores):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform final K-means clustering with optimal k\n",
    "optimal_k = 32\n",
    "print(f\"Performing final K-means clustering with k={optimal_k}...\")\n",
    "final_kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=20)\n",
    "kmeans_labels = final_kmeans.fit_predict(X_clustering)\n",
    "\n",
    "print(f\"Cluster distribution:\")\n",
    "unique, counts = np.unique(kmeans_labels, return_counts=True)\n",
    "for cluster, count in zip(unique, counts):\n",
    "    print(f\"Cluster {cluster}: {count} articles ({count/len(kmeans_labels)*100:.1f}%)\")\n",
    "\n",
    "# Calculate final metrics\n",
    "final_silhouette = silhouette_score(X_clustering, kmeans_labels)\n",
    "final_calinski = calinski_harabasz_score(X_clustering, kmeans_labels)\n",
    "final_davies_bouldin = davies_bouldin_score(X_clustering, kmeans_labels)\n",
    "\n",
    "print(f\"\\nFinal clustering metrics:\")\n",
    "print(f\"Silhouette Score: {final_silhouette:.3f}\")\n",
    "print(f\"Calinski-Harabasz Score: {final_calinski:.3f}\")\n",
    "print(f\"Davies-Bouldin Score: {final_davies_bouldin:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## 4. Visualise K-means Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise K-means clusters on t-SNE\n",
    "plt.figure(figsize=(12, 10))\n",
    "scatter = plt.scatter(embeddings_tsne[:, 0], embeddings_tsne[:, 1], \n",
    "                     c=kmeans_labels, cmap='tab10', alpha=0.7, s=2)\n",
    "plt.xlabel('t-SNE 1')\n",
    "plt.ylabel('t-SNE 2')\n",
    "plt.title(f'K-means Clustering (k={optimal_k}) - t-SNE Visualisation')\n",
    "plt.colorbar(scatter, label='Cluster')\n",
    "plt.show()\n",
    "\n",
    "# Interactive plotly visualisation\n",
    "fig = px.scatter(x=embeddings_tsne[:, 0], y=embeddings_tsne[:, 1], \n",
    "                color=kmeans_labels.astype(str),\n",
    "                hover_data={'article_id': article_ids},\n",
    "                title=f'K-means Clustering (k={optimal_k}) - Interactive t-SNE',\n",
    "                labels={'x': 't-SNE 1', 'y': 't-SNE 2', 'color': 'Cluster'})\n",
    "fig.update_traces(marker=dict(size=3, opacity=0.7))\n",
    "fig.show()\n",
    "\n",
    "# Save interactive plot\n",
    "fig.write_html('../../results/clustering/bert_kmeans_tsne_interactive.html')\n",
    "print(\"Interactive plot saved to results/clustering/bert_kmeans_tsne_interactive.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UMAP visualisation if available\n",
    "if UMAP_AVAILABLE and embeddings_umap is not None:\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    scatter = plt.scatter(embeddings_umap[:, 0], embeddings_umap[:, 1], \n",
    "                         c=kmeans_labels, cmap='tab10', alpha=0.7, s=2)\n",
    "    plt.xlabel('UMAP 1')\n",
    "    plt.ylabel('UMAP 2')\n",
    "    plt.title(f'K-means Clustering (k={optimal_k}) - UMAP Visualisation')\n",
    "    plt.colorbar(scatter, label='Cluster')\n",
    "    plt.show()\n",
    "    \n",
    "    # Interactive UMAP\n",
    "    fig = px.scatter(x=embeddings_umap[:, 0], y=embeddings_umap[:, 1], \n",
    "                    color=kmeans_labels.astype(str),\n",
    "                    hover_data={'article_id': article_ids},\n",
    "                    title=f'K-means Clustering (k={optimal_k}) - Interactive UMAP',\n",
    "                    labels={'x': 'UMAP 1', 'y': 'UMAP 2', 'color': 'Cluster'})\n",
    "    fig.update_traces(marker=dict(size=3, opacity=0.7))\n",
    "    fig.show()\n",
    "    \n",
    "    fig.write_html('../../results/clustering/bert_kmeans_umap_interactive.html')\n",
    "    print(\"UMAP interactive plot saved to results/clustering/bert_kmeans_umap_interactive.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## 5. Hierarchical Clustering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hierarchical clustering with a sample for computational efficiency\n",
    "sample_size = min(5000, len(embeddings_pca))  # Use subset for dendrogram\n",
    "sample_idx = np.random.choice(len(embeddings_pca), sample_size, replace=False)\n",
    "X_sample = embeddings_pca[sample_idx]\n",
    "\n",
    "print(f\"Performing hierarchical clustering on sample of {sample_size} articles...\")\n",
    "\n",
    "# Compute linkage matrix\n",
    "linkage_matrix = linkage(X_sample, method='ward')\n",
    "\n",
    "# Plot dendrogram\n",
    "plt.figure(figsize=(15, 8))\n",
    "dendrogram(linkage_matrix, truncate_mode='level', p=6)\n",
    "plt.xlabel('Sample Index or Cluster Size')\n",
    "plt.ylabel('Distance')\n",
    "plt.title('Hierarchical Clustering Dendrogram (Sample)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform hierarchical clustering on full dataset\n",
    "print(f\"Performing hierarchical clustering on full dataset with {optimal_k} clusters...\")\n",
    "hierarchical = AgglomerativeClustering(n_clusters=optimal_k, linkage='ward')\n",
    "hierarchical_labels = hierarchical.fit_predict(X_clustering)\n",
    "\n",
    "print(f\"Hierarchical cluster distribution:\")\n",
    "unique, counts = np.unique(hierarchical_labels, return_counts=True)\n",
    "for cluster, count in zip(unique, counts):\n",
    "    print(f\"Cluster {cluster}: {count} articles ({count/len(hierarchical_labels)*100:.1f}%)\")\n",
    "\n",
    "# Calculate metrics\n",
    "hier_silhouette = silhouette_score(X_clustering, hierarchical_labels)\n",
    "hier_calinski = calinski_harabasz_score(X_clustering, hierarchical_labels)\n",
    "hier_davies_bouldin = davies_bouldin_score(X_clustering, hierarchical_labels)\n",
    "\n",
    "print(f\"\\nHierarchical clustering metrics:\")\n",
    "print(f\"Silhouette Score: {hier_silhouette:.3f}\")\n",
    "print(f\"Calinski-Harabasz Score: {hier_calinski:.3f}\")\n",
    "print(f\"Davies-Bouldin Score: {hier_davies_bouldin:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise hierarchical clustering results\n",
    "plt.figure(figsize=(12, 10))\n",
    "scatter = plt.scatter(embeddings_tsne[:, 0], embeddings_tsne[:, 1], \n",
    "                     c=hierarchical_labels, cmap='tab10', alpha=0.7, s=2)\n",
    "plt.xlabel('t-SNE 1')\n",
    "plt.ylabel('t-SNE 2')\n",
    "plt.title(f'Hierarchical Clustering ({optimal_k} clusters) - t-SNE Visualisation')\n",
    "plt.colorbar(scatter, label='Cluster')\n",
    "plt.show()\n",
    "\n",
    "# Interactive plot\n",
    "fig = px.scatter(x=embeddings_tsne[:, 0], y=embeddings_tsne[:, 1], \n",
    "                color=hierarchical_labels.astype(str),\n",
    "                hover_data={'article_id': article_ids},\n",
    "                title=f'Hierarchical Clustering ({optimal_k} clusters) - Interactive t-SNE',\n",
    "                labels={'x': 't-SNE 1', 'y': 't-SNE 2', 'color': 'Cluster'})\n",
    "fig.update_traces(marker=dict(size=3, opacity=0.7))\n",
    "fig.show()\n",
    "\n",
    "fig.write_html('../../results/clustering/bert_hierarchical_tsne_interactive.html')\n",
    "print(\"Hierarchical clustering interactive plot saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "## 6. HDBSCAN Clustering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "if HDBSCAN_AVAILABLE:\n",
    "    print(\"Performing HDBSCAN clustering...\")\n",
    "    \n",
    "    # Try different min_cluster_size values\n",
    "    min_sizes = [50, 100, 200, 500]\n",
    "    hdbscan_results = []\n",
    "    \n",
    "    for min_size in min_sizes:\n",
    "        clusterer = hdbscan.HDBSCAN(min_cluster_size=min_size, min_samples=10)\n",
    "        cluster_labels = clusterer.fit_predict(X_clustering)\n",
    "        \n",
    "        n_clusters = len(set(cluster_labels)) - (1 if -1 in cluster_labels else 0)\n",
    "        n_noise = list(cluster_labels).count(-1)\n",
    "        \n",
    "        if n_clusters > 1:\n",
    "            silhouette = silhouette_score(X_clustering[cluster_labels != -1], \n",
    "                                        cluster_labels[cluster_labels != -1])\n",
    "        else:\n",
    "            silhouette = -1\n",
    "        \n",
    "        hdbscan_results.append({\n",
    "            'min_size': min_size,\n",
    "            'n_clusters': n_clusters,\n",
    "            'n_noise': n_noise,\n",
    "            'silhouette': silhouette,\n",
    "            'labels': cluster_labels\n",
    "        })\n",
    "        \n",
    "        print(f\"Min size {min_size}: {n_clusters} clusters, {n_noise} noise points, silhouette: {silhouette:.3f}\")\n",
    "    \n",
    "    # Choose best HDBSCAN result\n",
    "    best_hdbscan = max(hdbscan_results, key=lambda x: x['silhouette'] if x['silhouette'] > 0 else -1)\n",
    "    hdbscan_labels = best_hdbscan['labels']\n",
    "    \n",
    "    print(f\"\\nBest HDBSCAN result:\")\n",
    "    print(f\"Min cluster size: {best_hdbscan['min_size']}\")\n",
    "    print(f\"Number of clusters: {best_hdbscan['n_clusters']}\")\n",
    "    print(f\"Noise points: {best_hdbscan['n_noise']} ({best_hdbscan['n_noise']/len(hdbscan_labels)*100:.1f}%)\")\n",
    "    print(f\"Silhouette score: {best_hdbscan['silhouette']:.3f}\")\n",
    "    \n",
    "else:\n",
    "    print(\"HDBSCAN not available - skipping\")\n",
    "    hdbscan_labels = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "if HDBSCAN_AVAILABLE and hdbscan_labels is not None:\n",
    "    # Visualise HDBSCAN results\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    scatter = plt.scatter(embeddings_tsne[:, 0], embeddings_tsne[:, 1], \n",
    "                         c=hdbscan_labels, cmap='tab10', alpha=0.7, s=2)\n",
    "    plt.xlabel('t-SNE 1')\n",
    "    plt.ylabel('t-SNE 2')\n",
    "    plt.title(f'HDBSCAN Clustering - t-SNE Visualisation')\n",
    "    plt.colorbar(scatter, label='Cluster')\n",
    "    plt.show()\n",
    "    \n",
    "    # Interactive plot\n",
    "    fig = px.scatter(x=embeddings_tsne[:, 0], y=embeddings_tsne[:, 1], \n",
    "                    color=hdbscan_labels.astype(str),\n",
    "                    hover_data={'article_id': article_ids},\n",
    "                    title='HDBSCAN Clustering - Interactive t-SNE',\n",
    "                    labels={'x': 't-SNE 1', 'y': 't-SNE 2', 'color': 'Cluster'})\n",
    "    fig.update_traces(marker=dict(size=3, opacity=0.7))\n",
    "    fig.show()\n",
    "    \n",
    "    fig.write_html('../../results/clustering/bert_hdbscan_tsne_interactive.html')\n",
    "    print(\"HDBSCAN interactive plot saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "## 7. Clustering Comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different clustering methods\n",
    "comparison_data = {\n",
    "    'Method': ['K-means', 'Hierarchical'],\n",
    "    'Silhouette Score': [final_silhouette, hier_silhouette],\n",
    "    'Calinski-Harabasz Score': [final_calinski, hier_calinski],\n",
    "    'Davies-Bouldin Score': [final_davies_bouldin, hier_davies_bouldin]\n",
    "}\n",
    "\n",
    "if HDBSCAN_AVAILABLE and hdbscan_labels is not None:\n",
    "    comparison_data['Method'].append('HDBSCAN')\n",
    "    comparison_data['Silhouette Score'].append(best_hdbscan['silhouette'])\n",
    "    comparison_data['Calinski-Harabasz Score'].append('N/A')\n",
    "    comparison_data['Davies-Bouldin Score'].append('N/A')\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(\"Clustering Method Comparison:\")\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Plot comparison\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "methods = comparison_df['Method'].tolist()\n",
    "silhouette_vals = [x for x in comparison_df['Silhouette Score'] if isinstance(x, float)]\n",
    "methods_numeric = [m for i, m in enumerate(methods) if isinstance(comparison_df.iloc[i]['Silhouette Score'], float)]\n",
    "\n",
    "axes[0].bar(methods_numeric, silhouette_vals)\n",
    "axes[0].set_title('Silhouette Score Comparison')\n",
    "axes[0].set_ylabel('Score')\n",
    "\n",
    "calinski_vals = [x for x in comparison_df['Calinski-Harabasz Score'] if isinstance(x, (int, float))]\n",
    "methods_calinski = [m for i, m in enumerate(methods) if isinstance(comparison_df.iloc[i]['Calinski-Harabasz Score'], (int, float))]\n",
    "\n",
    "if calinski_vals:\n",
    "    axes[1].bar(methods_calinski, calinski_vals)\n",
    "axes[1].set_title('Calinski-Harabasz Score Comparison')\n",
    "axes[1].set_ylabel('Score')\n",
    "\n",
    "davies_vals = [x for x in comparison_df['Davies-Bouldin Score'] if isinstance(x, (int, float))]\n",
    "methods_davies = [m for i, m in enumerate(methods) if isinstance(comparison_df.iloc[i]['Davies-Bouldin Score'], (int, float))]\n",
    "\n",
    "if davies_vals:\n",
    "    axes[2].bar(methods_davies, davies_vals)\n",
    "axes[2].set_title('Davies-Bouldin Score Comparison (Lower is Better)')\n",
    "axes[2].set_ylabel('Score')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "## 8. Save Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results dataframe\n",
    "results_df = pl.DataFrame({\n",
    "    'article_id': article_ids,\n",
    "    'kmeans_cluster': kmeans_labels,\n",
    "    'hierarchical_cluster': hierarchical_labels,\n",
    "    'tsne_1': embeddings_tsne[:, 0],\n",
    "    'tsne_2': embeddings_tsne[:, 1]\n",
    "})\n",
    "\n",
    "if HDBSCAN_AVAILABLE and hdbscan_labels is not None:\n",
    "    results_df = results_df.with_columns(\n",
    "        pl.Series('hdbscan_cluster', hdbscan_labels)\n",
    "    )\n",
    "\n",
    "if UMAP_AVAILABLE and embeddings_umap is not None:\n",
    "    results_df = results_df.with_columns([\n",
    "        pl.Series('umap_1', embeddings_umap[:, 0]),\n",
    "        pl.Series('umap_2', embeddings_umap[:, 1])\n",
    "    ])\n",
    "\n",
    "# Save results\n",
    "results_df.write_parquet('../../results/clustering/bert_embeddings_clustering_results.parquet')\n",
    "results_df.write_csv('../../results/clustering/bert_embeddings_clustering_results.csv')\n",
    "\n",
    "print(f\"Results saved:\")\n",
    "print(f\"- Parquet: results/clustering/bert_embeddings_clustering_results.parquet\")\n",
    "print(f\"- CSV: results/clustering/bert_embeddings_clustering_results.csv\")\n",
    "print(f\"\\nResults shape: {results_df.shape}\")\n",
    "print(f\"Columns: {results_df.columns}\")\n",
    "\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook performed comprehensive clustering analysis on H&M product BERT embeddings:\n",
    "\n",
    "### Data\n",
    "\n",
    "- 42,229 articles with 768-dimensional BERT embeddings\n",
    "- Used PCA (50 components) for computational efficiency\n",
    "- Applied t-SNE and UMAP for 2D visualisation\n",
    "\n",
    "### Clustering Methods\n",
    "\n",
    "1. **K-means**: Determined optimal k using multiple metrics\n",
    "2. **Hierarchical**: Ward linkage with dendrogram analysis\n",
    "3. **HDBSCAN**: Density-based clustering for natural cluster detection\n",
    "\n",
    "### Results\n",
    "\n",
    "- Interactive visualisations saved to `results/clustering/`\n",
    "- Clustering assignments and 2D coordinates saved for further analysis\n",
    "- Performance metrics calculated for method comparison\n",
    "\n",
    "The BERT embeddings enable semantic clustering of products based on textual descriptions, revealing natural product groupings that can support recommendation systems and inventory categorisation.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
