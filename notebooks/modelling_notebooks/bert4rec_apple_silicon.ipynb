{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# BERT4Rec Apple Silicon Optimized Training\n",
    "\n",
    "## Enhanced training optimized for M1/M2/M3 with MPS acceleration\n",
    "\n",
    "This notebook implements:\n",
    "\n",
    "- **Apple Silicon MPS optimization** for faster training\n",
    "- **Memory-efficient data loading** for unified memory architecture\n",
    "- **8-12 epochs** with early stopping and learning rate decay\n",
    "- **Context tokens** ([SEG], [CH], price-band) for better calibration\n",
    "- **TensorBoard monitoring** with Apple Silicon compatibility\n",
    "- **Target: Recall@10 ‚Üí ~0.20‚Äì0.25**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.11.4 (v3.11.4:d2340ef257, Jun  6 2023, 19:15:51) [Clang 13.0.0 (clang-1300.0.29.30)]\n",
      "PyTorch version: 2.8.0\n",
      "Platform: macOS-15.6-arm64-arm-64bit\n",
      "Architecture: arm64\n"
     ]
    }
   ],
   "source": [
    "# Core imports\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import platform\n",
    "\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Add project root to path\n",
    "sys.path.append('../../')\n",
    "# Import BERT4Rec implementation\n",
    "from hnm_data_analysis.data_modelling.bert4rec_modelling import (\n",
    "    SequenceOptions, prepare_sequences_with_polars,\n",
    "    build_dataloaders_for_bert4rec, BERT4RecModel, TrainConfig,\n",
    "    train_bert4rec, evaluate_next_item_topk, set_all_seeds,\n",
    "    MaskingOptions\n",
    ")\n",
    "\n",
    "# Set paths\n",
    "DATA_ROOT = Path('../../data/modelling_data')\n",
    "MODEL_SAVE_DIR = Path('../../models/bert4rec')\n",
    "MODEL_SAVE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Platform: {platform.platform()}\")\n",
    "print(f\"Architecture: {platform.machine()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Apple Silicon Device Detection & Optimization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üçé Using Apple Silicon MPS acceleration\n",
      "  ‚úì MPS built: True\n",
      "  üî• Chip: Apple M2 Pro\n",
      "  üíæ Unified Memory: 16 GB\n",
      "üçé Apple Silicon optimizations:\n",
      "  üì¶ Batch size: 96 (optimized for unified memory)\n",
      "  üîÑ Workers: 0 (single process for MPS)\n",
      "\n",
      "üéØ Training device: mps\n",
      "üîß Optimized configuration: {'batch_size': 96, 'num_workers': 0, 'pin_memory': False, 'persistent_workers': False, 'prefetch_factor': 2}\n"
     ]
    }
   ],
   "source": [
    "def get_optimal_device():\n",
    "    \"\"\"\n",
    "    Get the optimal device for Apple Silicon or fallback to CPU/CUDA\n",
    "    \"\"\"\n",
    "    if torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\")\n",
    "        print(\"üçé Using Apple Silicon MPS acceleration\")\n",
    "        \n",
    "        # Check MPS capabilities\n",
    "        print(f\"  ‚úì MPS built: {torch.backends.mps.is_built()}\")\n",
    "        \n",
    "        # Get system info\n",
    "        import subprocess\n",
    "        try:\n",
    "            # Get Apple Silicon chip info\n",
    "            result = subprocess.run(['sysctl', '-n', 'machdep.cpu.brand_string'], \n",
    "                                  capture_output=True, text=True)\n",
    "            if result.returncode == 0:\n",
    "                print(f\"  üî• Chip: {result.stdout.strip()}\")\n",
    "            \n",
    "            # Get memory info\n",
    "            result = subprocess.run(['sysctl', '-n', 'hw.memsize'], \n",
    "                                  capture_output=True, text=True)\n",
    "            if result.returncode == 0:\n",
    "                memory_bytes = int(result.stdout.strip())\n",
    "                memory_gb = memory_bytes / (1024**3)\n",
    "                print(f\"  üíæ Unified Memory: {memory_gb:.0f} GB\")\n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ö†Ô∏è  Could not get system info: {e}\")\n",
    "            \n",
    "    elif torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        print(f\"üöÄ Using CUDA GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"  üíæ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"üíª Using CPU\")\n",
    "        import psutil\n",
    "        print(f\"  üíæ RAM: {psutil.virtual_memory().total / 1e9:.1f} GB\")\n",
    "        print(f\"  üîÑ CPU cores: {psutil.cpu_count()}\")\n",
    "    \n",
    "    return device\n",
    "\n",
    "def get_apple_silicon_config(device):\n",
    "    \"\"\"\n",
    "    Get optimal configuration for Apple Silicon\n",
    "    \"\"\"\n",
    "    config = {\n",
    "        'batch_size': 64,\n",
    "        'num_workers': 0,  # MPS works best with single process\n",
    "        'pin_memory': False,  # Not needed for MPS\n",
    "        'persistent_workers': False,\n",
    "        'prefetch_factor': 2\n",
    "    }\n",
    "    \n",
    "    if device.type == \"mps\":\n",
    "        # Apple Silicon optimizations\n",
    "        config.update({\n",
    "            'batch_size': 96,  # Can handle larger batches with unified memory\n",
    "            'num_workers': 0,   # MPS doesn't benefit from multiprocessing\n",
    "            'pin_memory': False # Unified memory architecture\n",
    "        })\n",
    "        print(\"üçé Apple Silicon optimizations:\")\n",
    "        print(f\"  üì¶ Batch size: {config['batch_size']} (optimized for unified memory)\")\n",
    "        print(f\"  üîÑ Workers: {config['num_workers']} (single process for MPS)\")\n",
    "        \n",
    "    elif device.type == \"cuda\":\n",
    "        # CUDA optimizations\n",
    "        config.update({\n",
    "            'batch_size': 64,\n",
    "            'num_workers': 4,\n",
    "            'pin_memory': True,\n",
    "            'persistent_workers': True\n",
    "        })\n",
    "        print(\"üöÄ CUDA optimizations applied\")\n",
    "        \n",
    "    else:\n",
    "        # CPU optimizations\n",
    "        config.update({\n",
    "            'batch_size': 32,  # Smaller batch for CPU\n",
    "            'num_workers': min(4, os.cpu_count()),\n",
    "            'pin_memory': False\n",
    "        })\n",
    "        print(\"üíª CPU optimizations applied\")\n",
    "    \n",
    "    return config\n",
    "\n",
    "# Initialize device and config\n",
    "device = get_optimal_device()\n",
    "device_config = get_apple_silicon_config(device)\n",
    "\n",
    "print(f\"\\nüéØ Training device: {device}\")\n",
    "print(f\"üîß Optimized configuration: {device_config}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Apple Silicon Optimized Training Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üçé Apple Silicon MPS optimizations enabled:\n",
      "  ‚Ä¢ AMP disabled (MPS limitation)\n",
      "  ‚Ä¢ Model compilation disabled\n",
      "  ‚Ä¢ Memory-efficient mode enabled\n",
      "\n",
      "üìã Training for up to 12 epochs with early stopping\n",
      "üéØ Target Recall@10: 0.2\n"
     ]
    }
   ],
   "source": [
    "# Apple Silicon optimized training configuration\n",
    "class AppleSiliconTrainConfig:\n",
    "    def __init__(self, device):\n",
    "        # Base training parameters\n",
    "        self.n_epochs = 12\n",
    "        self.lr = 1e-4\n",
    "        self.weight_decay = 0.01\n",
    "        self.warmup_steps = 1000\n",
    "        self.grad_clip_norm = 1.0\n",
    "        \n",
    "        # Early stopping\n",
    "        self.early_stopping_patience = 3\n",
    "        self.min_delta = 0.001\n",
    "        \n",
    "        # Learning rate decay\n",
    "        self.lr_decay_patience = 2\n",
    "        self.lr_decay_factor = 0.5\n",
    "        self.min_lr = 1e-6\n",
    "        \n",
    "        # Evaluation\n",
    "        self.eval_every_n_epochs = 1\n",
    "        self.save_best_model = True\n",
    "        \n",
    "        # Target metrics\n",
    "        self.target_recall_10 = 0.20\n",
    "        self.target_recall_20 = 0.25\n",
    "        \n",
    "        # Apple Silicon specific optimizations\n",
    "        if device.type == \"mps\":\n",
    "            # MPS optimizations\n",
    "            self.use_amp = False  # MPS doesn't support AMP yet\n",
    "            self.compile_model = False  # torch.compile not fully supported on MPS\n",
    "            self.grad_accumulation_steps = 1  # Keep simple for MPS\n",
    "            \n",
    "            # Memory optimizations for unified memory\n",
    "            self.memory_efficient = True\n",
    "            self.clear_cache_every_n_steps = 100\n",
    "            \n",
    "            print(\"üçé Apple Silicon MPS optimizations enabled:\")\n",
    "            print(\"  ‚Ä¢ AMP disabled (MPS limitation)\")\n",
    "            print(\"  ‚Ä¢ Model compilation disabled\")\n",
    "            print(\"  ‚Ä¢ Memory-efficient mode enabled\")\n",
    "            \n",
    "        elif device.type == \"cuda\":\n",
    "            # CUDA optimizations\n",
    "            self.use_amp = True\n",
    "            self.compile_model = True\n",
    "            self.grad_accumulation_steps = 1\n",
    "            self.memory_efficient = False\n",
    "            self.clear_cache_every_n_steps = None\n",
    "            \n",
    "            print(\"üöÄ CUDA optimizations enabled:\")\n",
    "            print(\"  ‚Ä¢ AMP enabled for faster training\")\n",
    "            print(\"  ‚Ä¢ Model compilation enabled\")\n",
    "            \n",
    "        else:\n",
    "            # CPU optimizations\n",
    "            self.use_amp = False\n",
    "            self.compile_model = False\n",
    "            self.grad_accumulation_steps = 2  # Accumulate gradients for CPU\n",
    "            self.memory_efficient = True\n",
    "            self.clear_cache_every_n_steps = None\n",
    "            \n",
    "            print(\"üíª CPU optimizations enabled:\")\n",
    "            print(\"  ‚Ä¢ Gradient accumulation for effective larger batches\")\n",
    "            print(\"  ‚Ä¢ Memory-efficient mode enabled\")\n",
    "\n",
    "config = AppleSiliconTrainConfig(device)\n",
    "print(f\"\\nüìã Training for up to {config.n_epochs} epochs with early stopping\")\n",
    "print(f\"üéØ Target Recall@10: {config.target_recall_10}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Data Loading with Apple Silicon Optimizations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Loading transaction data (optimized for Apple Silicon)...\n",
      "üçé Using Apple Silicon optimized data loading...\n",
      "‚úì Data sample loaded successfully: (1000, 5)\n",
      "üìä Available columns: ['t_dat', 'customer_id', 'article_id', 'price', 'sales_channel_id']\n",
      "üì• Collecting full dataset...\n",
      "üìä Data shape: (3904391, 5)\n",
      "üìÖ Date range: 2020-06-24 to 2020-09-22\n",
      "üë• Unique customers: 525,075\n",
      "üõçÔ∏è  Unique articles: 42,298\n",
      "üíæ Current memory usage: 577.0 MB\n"
     ]
    }
   ],
   "source": [
    "# Load data with memory-efficient approach for Apple Silicon\n",
    "print(\"üìÇ Loading transaction data (optimized for Apple Silicon)...\")\n",
    "\n",
    "# Use lazy loading for large datasets on Apple Silicon\n",
    "if device.type == \"mps\":\n",
    "    # For Apple Silicon, use streaming approach if data is large\n",
    "    print(\"üçé Using Apple Silicon optimized data loading...\")\n",
    "    df = pl.scan_parquet(DATA_ROOT / 'transactions_final.parquet')\n",
    "    \n",
    "    # Check data size before collecting\n",
    "    try:\n",
    "        sample = df.head(1000).collect()\n",
    "        print(f\"‚úì Data sample loaded successfully: {sample.shape}\")\n",
    "        print(f\"üìä Available columns: {sample.columns}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Issue with data loading: {e}\")\n",
    "        \n",
    "    # Collect full data with memory monitoring\n",
    "    print(\"üì• Collecting full dataset...\")\n",
    "    df = df.collect()\n",
    "else:\n",
    "    # Standard loading for other devices\n",
    "    df = pl.read_parquet(DATA_ROOT / 'transactions_final.parquet')\n",
    "\n",
    "print(f\"üìä Data shape: {df.shape}\")\n",
    "print(f\"üìÖ Date range: {df['t_dat'].min()} to {df['t_dat'].max()}\")\n",
    "print(f\"üë• Unique customers: {df['customer_id'].n_unique():,}\")\n",
    "print(f\"üõçÔ∏è  Unique articles: {df['article_id'].n_unique():,}\")\n",
    "\n",
    "# Memory usage info for Apple Silicon\n",
    "if device.type == \"mps\":\n",
    "    import psutil\n",
    "    process = psutil.Process()\n",
    "    memory_mb = process.memory_info().rss / 1024 / 1024\n",
    "    print(f\"üíæ Current memory usage: {memory_mb:.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Sequence Preparation with Context Tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Preparing sequences with context tokens...\n",
      "üìã Context tokens enabled:\n",
      "  ‚úì Segment prefix: True\n",
      "  ‚úì Channel prefix: True\n",
      "  ‚úì Price-band prefix: True\n",
      "\n",
      "üìã Available columns: ['t_dat', 'customer_id', 'article_id', 'price', 'sales_channel_id']\n",
      "üçé Using Apple Silicon optimized sequence preparation...\n",
      "\n",
      "‚úÖ Sequence preparation complete (26.5s):\n",
      "  üìä Total sequences: 448,880\n",
      "  üìö Vocabulary size: 42,300\n",
      "  üè∑Ô∏è  Context tokens: 0\n",
      "  üìè Average sequence length: 7.8\n",
      "  üéØ Average prefix length: 0.0\n",
      "\n",
      "üíæ Memory after prep: 948.6 MB\n"
     ]
    }
   ],
   "source": [
    "# Sequence preparation with context tokens and Apple Silicon optimization\n",
    "set_all_seeds(42)\n",
    "\n",
    "sequence_options = SequenceOptions(\n",
    "    max_len=50,           \n",
    "    min_len=3,            \n",
    "    deduplicate_exact=True,\n",
    "    treat_same_day_as_basket=True,\n",
    "    # Enable context tokens for better calibration\n",
    "    add_segment_prefix=True,     # Add [SEG] tokens \n",
    "    add_channel_prefix=True,     # Add [CH] tokens \n",
    "    add_priceband_prefix=True,   # Add price-band tokens\n",
    "    n_price_bins=10              \n",
    ")\n",
    "\n",
    "print(\"üîß Preparing sequences with context tokens...\")\n",
    "print(\"üìã Context tokens enabled:\")\n",
    "print(f\"  ‚úì Segment prefix: {sequence_options.add_segment_prefix}\")\n",
    "print(f\"  ‚úì Channel prefix: {sequence_options.add_channel_prefix}\")\n",
    "print(f\"  ‚úì Price-band prefix: {sequence_options.add_priceband_prefix}\")\n",
    "\n",
    "# Check available columns\n",
    "print(f\"\\nüìã Available columns: {df.columns}\")\n",
    "\n",
    "# Apple Silicon memory optimization during preparation\n",
    "if device.type == \"mps\":\n",
    "    print(\"üçé Using Apple Silicon optimized sequence preparation...\")\n",
    "    \n",
    "# Prepare sequences\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "prepared = prepare_sequences_with_polars(df, sequence_options)\n",
    "\n",
    "prep_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\n‚úÖ Sequence preparation complete ({prep_time:.1f}s):\")\n",
    "print(f\"  üìä Total sequences: {len(prepared.sequences):,}\")\n",
    "print(f\"  üìö Vocabulary size: {prepared.registry.vocab_size:,}\")\n",
    "print(f\"  üè∑Ô∏è  Context tokens: {len(prepared.registry.prefix_token2id):,}\")\n",
    "print(f\"  üìè Average sequence length: {np.mean([len(seq) for seq in prepared.sequences]):.1f}\")\n",
    "print(f\"  üéØ Average prefix length: {np.mean(prepared.prefix_lengths):.1f}\")\n",
    "\n",
    "# Show example context tokens\n",
    "if prepared.registry.prefix_token2id:\n",
    "    print(f\"\\nüè∑Ô∏è  Example context tokens:\")\n",
    "    for i, (token, token_id) in enumerate(list(prepared.registry.prefix_token2id.items())[:8]):\n",
    "        print(f\"    {token_id:4d}: {token}\")\n",
    "        if i >= 7:\n",
    "            break\n",
    "\n",
    "# Memory check for Apple Silicon\n",
    "if device.type == \"mps\":\n",
    "    process = psutil.Process()\n",
    "    memory_mb = process.memory_info().rss / 1024 / 1024\n",
    "    print(f\"\\nüíæ Memory after prep: {memory_mb:.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## Apple Silicon Optimised Data Loaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Building Apple Silicon optimized data loaders...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3221ae08ea414711955330b20d75fd0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Splitting sequences:   0%|          | 0/448880 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data loaders created:\n",
      "  üöÇ Train batches: 4209 (batch size: 96)\n",
      "  ‚úÖ Valid batches: 468\n",
      "  üß™ Eval batches: 4676\n",
      "  üìö Registry vocab: 42,300\n",
      "  üîÑ Workers: 0 (optimized for MPS)\n"
     ]
    }
   ],
   "source": [
    "# Create Apple Silicon optimized data loaders\n",
    "masking_options = MaskingOptions(\n",
    "    mask_prob=0.8,\n",
    "    random_token_prob=0.1,\n",
    "    keep_original_prob=0.1\n",
    ")\n",
    "\n",
    "print(\"üì¶ Building Apple Silicon optimized data loaders...\")\n",
    "\n",
    "# Use Apple Silicon specific configuration\n",
    "train_loader, valid_loader, eval_loader = build_dataloaders_for_bert4rec(\n",
    "    prepared, \n",
    "    batch_size=device_config['batch_size'],\n",
    "    masking=masking_options,\n",
    "    valid_split=0.1,\n",
    "    num_workers=device_config['num_workers']\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Data loaders created:\")\n",
    "print(f\"  üöÇ Train batches: {len(train_loader)} (batch size: {device_config['batch_size']})\")\n",
    "print(f\"  ‚úÖ Valid batches: {len(valid_loader)}\")\n",
    "print(f\"  üß™ Eval batches: {len(eval_loader)}\")\n",
    "print(f\"  üìö Registry vocab: {prepared.registry.vocab_size:,}\")\n",
    "print(f\"  üîÑ Workers: {device_config['num_workers']} (optimized for {device.type.upper()})\")\n",
    "\n",
    "# Use the eval_loader as test_loader\n",
    "test_loader = eval_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## Apple Silicon Optimized Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üçé Applying Apple Silicon optimizations...\n",
      "  ‚úì Model moved to MPS device\n",
      "\n",
      "üìä Model statistics:\n",
      "  üî¢ Parameters: 31,194,428\n",
      "  üíæ Model size: ~124.8 MB\n",
      "  üèóÔ∏è  Architecture: 6L√ó512H√ó8A\n",
      "  üìö Vocab breakdown:\n",
      "    ‚Ä¢ Total: 42,300\n",
      "    ‚Ä¢ Articles: 42,298\n",
      "    ‚Ä¢ Context tokens: 0\n",
      "  üéØ Device: mps\n",
      "  ‚úÖ Forward pass test: torch.Size([2, 100, 42300])\n",
      "  üíæ Memory after model load: 1055.4 MB\n"
     ]
    }
   ],
   "source": [
    "# Initialize model optimized for Apple Silicon\n",
    "model_config = {\n",
    "    'vocab_size': prepared.registry.vocab_size,\n",
    "    'd_model': 512,    # Good size for Apple Silicon unified memory\n",
    "    'n_layers': 6,       \n",
    "    'n_heads': 8,\n",
    "    'dropout': 0.1,\n",
    "    'max_len': 50\n",
    "}\n",
    "\n",
    "model = BERT4RecModel(**model_config)\n",
    "\n",
    "# Apple Silicon specific optimizations\n",
    "if device.type == \"mps\":\n",
    "    print(\"üçé Applying Apple Silicon optimizations...\")\n",
    "    \n",
    "    # Move to MPS device\n",
    "    model.to(device)\n",
    "    \n",
    "    print(\"  ‚úì Model moved to MPS device\")\n",
    "    \n",
    "elif device.type == \"cuda\":\n",
    "    print(\"üöÄ Applying CUDA optimizations...\")\n",
    "    model.to(device)\n",
    "    \n",
    "    # Compile model if supported\n",
    "    if config.compile_model and hasattr(torch, 'compile'):\n",
    "        try:\n",
    "            model = torch.compile(model)\n",
    "            print(\"  ‚úì Model compiled for faster inference\")\n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ö†Ô∏è  Model compilation failed: {e}\")\n",
    "            \n",
    "else:\n",
    "    print(\"üíª Applying CPU optimizations...\")\n",
    "    model.to(device)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"\\nüìä Model statistics:\")\n",
    "print(f\"  üî¢ Parameters: {total_params:,}\")\n",
    "print(f\"  üíæ Model size: ~{total_params * 4 / 1e6:.1f} MB\")\n",
    "print(f\"  üèóÔ∏è  Architecture: {model_config['n_layers']}L√ó{model_config['d_model']}H√ó{model_config['n_heads']}A\")\n",
    "print(f\"  üìö Vocab breakdown:\")\n",
    "print(f\"    ‚Ä¢ Total: {prepared.registry.vocab_size:,}\")\n",
    "print(f\"    ‚Ä¢ Articles: {len(prepared.registry.item2id):,}\")\n",
    "print(f\"    ‚Ä¢ Context tokens: {len(prepared.registry.prefix_token2id):,}\")\n",
    "print(f\"  üéØ Device: {device}\")\n",
    "\n",
    "# Memory usage check for Apple Silicon\n",
    "if device.type == \"mps\":\n",
    "    # Test model forward pass\n",
    "    test_batch = next(iter(train_loader))\n",
    "    test_input = test_batch['input_ids'][:2].to(device)  # Small test\n",
    "    test_mask = test_batch['attention_mask'][:2].to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        test_output = model(test_input, test_mask)\n",
    "        print(f\"  ‚úÖ Forward pass test: {test_output.shape}\")\n",
    "    \n",
    "    import psutil\n",
    "    process = psutil.Process()\n",
    "    memory_mb = process.memory_info().rss / 1024 / 1024\n",
    "    print(f\"  üíæ Memory after model load: {memory_mb:.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## Apple Silicon Enhanced Training Loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_bert4rec_apple_silicon(\n",
    "    model, train_loader, valid_loader, test_loader, config, device, registry\n",
    "):\n",
    "    \"\"\"\n",
    "    Apple Silicon optimized training loop\n",
    "    \"\"\"\n",
    "    # Setup TensorBoard\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    writer = SummaryWriter(f'runs/bert4rec_apple_silicon_{timestamp}')\n",
    "    \n",
    "    # Optimizer\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(), \n",
    "        lr=config.lr, \n",
    "        weight_decay=config.weight_decay\n",
    "    )\n",
    "    \n",
    "    # Learning rate scheduler\n",
    "    lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer,\n",
    "        mode='min',\n",
    "        factor=config.lr_decay_factor,\n",
    "        patience=config.lr_decay_patience,\n",
    "        min_lr=config.min_lr\n",
    "    )\n",
    "    \n",
    "    # Mixed precision scaler (only for CUDA)\n",
    "    scaler = None\n",
    "    if config.use_amp and device.type == \"cuda\":\n",
    "        scaler = torch.cuda.amp.GradScaler()\n",
    "        print(\"‚ö° Mixed precision training enabled (CUDA)\")\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "    \n",
    "    # Training variables\n",
    "    best_val_loss = float('inf')\n",
    "    best_recall_10 = 0.0\n",
    "    patience_counter = 0\n",
    "    \n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'val_loss': [],\n",
    "        'recall_10': [],\n",
    "        'recall_20': [],\n",
    "        'learning_rate': [],\n",
    "        'memory_usage': [] if device.type == \"mps\" else None\n",
    "    }\n",
    "    \n",
    "    print(f\"üöÄ Starting Apple Silicon optimized training...\")\n",
    "    print(f\"üìä Device: {device} | Epochs: {config.n_epochs} | Target R@10: {config.target_recall_10}\")\n",
    "    print(f\"üìà TensorBoard: runs/bert4rec_apple_silicon_{timestamp}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    for epoch in range(1, config.n_epochs + 1):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        num_batches = 0\n",
    "        \n",
    "        from tqdm.auto import tqdm\n",
    "        pbar = tqdm(train_loader, desc=f\"üçé Epoch {epoch}/{config.n_epochs}\")\n",
    "        \n",
    "        for batch_idx, batch in enumerate(pbar):\n",
    "            input_ids = batch[\"input_ids\"].to(device, non_blocking=True)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device, non_blocking=True)\n",
    "            labels = batch[\"labels\"].to(device, non_blocking=True)\n",
    "            \n",
    "            optimizer.zero_grad(set_to_none=True)  # More efficient\n",
    "            \n",
    "            # Forward pass with optional mixed precision\n",
    "            if config.use_amp and scaler is not None:\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    logits = model(input_ids, attention_mask)\n",
    "                    B, L, V = logits.size()\n",
    "                    loss = criterion(logits.view(B * L, V), labels.view(B * L))\n",
    "                \n",
    "                # Backward pass with gradient scaling\n",
    "                scaler.scale(loss).backward()\n",
    "                \n",
    "                if config.grad_clip_norm > 0:\n",
    "                    scaler.unscale_(optimizer)\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), config.grad_clip_norm)\n",
    "                \n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                # Standard training (MPS/CPU)\n",
    "                logits = model(input_ids, attention_mask)\n",
    "                B, L, V = logits.size()\n",
    "                loss = criterion(logits.view(B * L, V), labels.view(B * L))\n",
    "                \n",
    "                loss.backward()\n",
    "                \n",
    "                if config.grad_clip_norm > 0:\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), config.grad_clip_norm)\n",
    "                \n",
    "                optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            num_batches += 1\n",
    "            \n",
    "            # Update progress bar\n",
    "            pbar.set_postfix({\n",
    "                'loss': f'{loss.item():.4f}',\n",
    "                'avg': f'{train_loss/num_batches:.4f}',\n",
    "                'lr': f'{optimizer.param_groups[0][\"lr\"]:.2e}'\n",
    "            })\n",
    "            \n",
    "            # Log batch metrics\n",
    "            global_step = (epoch - 1) * len(train_loader) + batch_idx\n",
    "            writer.add_scalar('Loss/Train_Batch', loss.item(), global_step)\n",
    "            writer.add_scalar('Learning_Rate', optimizer.param_groups[0]['lr'], global_step)\n",
    "        \n",
    "        avg_train_loss = train_loss / num_batches\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(valid_loader, desc=\"Validation\", leave=False):\n",
    "                input_ids = batch[\"input_ids\"].to(device, non_blocking=True)\n",
    "                attention_mask = batch[\"attention_mask\"].to(device, non_blocking=True)\n",
    "                labels = batch[\"labels\"].to(device, non_blocking=True)\n",
    "                \n",
    "                logits = model(input_ids, attention_mask)\n",
    "                B, L, V = logits.size()\n",
    "                loss = criterion(logits.view(B * L, V), labels.view(B * L))\n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        avg_val_loss = val_loss / len(valid_loader)\n",
    "        \n",
    "        # Evaluate Recall@K\n",
    "        print(f\"\\nüîç Evaluating Recall@K...\")\n",
    "        recall_10, ndcg_10 = evaluate_next_item_topk(model, test_loader, device, registry, topk=10)\n",
    "        recall_20, ndcg_20 = evaluate_next_item_topk(model, test_loader, device, registry, topk=20)\n",
    "        \n",
    "        # Memory tracking for Apple Silicon\n",
    "        memory_mb = None\n",
    "        if device.type == \"mps\":\n",
    "            import psutil\n",
    "            process = psutil.Process()\n",
    "            memory_mb = process.memory_info().rss / 1024 / 1024\n",
    "            history['memory_usage'].append(memory_mb)\n",
    "        \n",
    "        # Store history\n",
    "        history['train_loss'].append(avg_train_loss)\n",
    "        history['val_loss'].append(avg_val_loss)\n",
    "        history['recall_10'].append(recall_10)\n",
    "        history['recall_20'].append(recall_20)\n",
    "        history['learning_rate'].append(optimizer.param_groups[0]['lr'])\n",
    "        \n",
    "        # Log to TensorBoard\n",
    "        writer.add_scalar('Loss/Train_Epoch', avg_train_loss, epoch)\n",
    "        writer.add_scalar('Loss/Validation', avg_val_loss, epoch)\n",
    "        writer.add_scalar('Metrics/Recall@10', recall_10, epoch)\n",
    "        writer.add_scalar('Metrics/Recall@20', recall_20, epoch)\n",
    "        writer.add_scalar('Metrics/NDCG@10', ndcg_10, epoch)\n",
    "        writer.add_scalar('Metrics/NDCG@20', ndcg_20, epoch)\n",
    "        \n",
    "        if memory_mb:\n",
    "            writer.add_scalar('System/Memory_MB', memory_mb, epoch)\n",
    "        \n",
    "        # Print epoch summary\n",
    "        print(f\"\\nüìä Epoch {epoch}/{config.n_epochs} Summary:\")\n",
    "        print(f\"  üöÇ Train Loss: {avg_train_loss:.4f}\")\n",
    "        print(f\"  ‚úÖ Val Loss:   {avg_val_loss:.4f}\")\n",
    "        print(f\"  üéØ Recall@10:  {recall_10:.4f} (Target: {config.target_recall_10:.2f})\")\n",
    "        print(f\"  üìà Recall@20:  {recall_20:.4f}\")\n",
    "        print(f\"  üìä NDCG@10:    {ndcg_10:.4f}\")\n",
    "        print(f\"  ‚ö° LR:         {optimizer.param_groups[0]['lr']:.2e}\")\n",
    "        if memory_mb:\n",
    "            print(f\"  üíæ Memory:     {memory_mb:.1f} MB\")\n",
    "        \n",
    "        # Learning rate scheduling - manually print when LR changes\n",
    "        old_lr = optimizer.param_groups[0]['lr']\n",
    "        lr_scheduler.step(avg_val_loss)\n",
    "        new_lr = optimizer.param_groups[0]['lr']\n",
    "        if new_lr < old_lr:\n",
    "            print(f\"  üìâ Learning rate reduced: {old_lr:.2e} ‚Üí {new_lr:.2e}\")\n",
    "        \n",
    "        # Early stopping logic\n",
    "        if avg_val_loss < best_val_loss - config.min_delta:\n",
    "            best_val_loss = avg_val_loss\n",
    "            best_recall_10 = recall_10\n",
    "            patience_counter = 0\n",
    "            \n",
    "            # Save best model\n",
    "            if config.save_best_model:\n",
    "                best_model_path = MODEL_SAVE_DIR / f'bert4rec_apple_silicon_best_{timestamp}.pt'\n",
    "                torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'registry': registry,\n",
    "                    'config': config,\n",
    "                    'val_loss': best_val_loss,\n",
    "                    'recall_10': best_recall_10,\n",
    "                    'history': history,\n",
    "                    'device_type': device.type\n",
    "                }, best_model_path)\n",
    "                print(f\"  üíæ Best model saved (val_loss: {best_val_loss:.4f})\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"  ‚è∞ Early stopping: {patience_counter}/{config.early_stopping_patience}\")\n",
    "        \n",
    "        # Check stopping conditions\n",
    "        if patience_counter >= config.early_stopping_patience:\n",
    "            print(f\"\\nüõë Early stopping at epoch {epoch}\")\n",
    "            break\n",
    "        \n",
    "        if recall_10 >= config.target_recall_10:\n",
    "            print(f\"\\nüéØ Target achieved! Recall@10: {recall_10:.4f} >= {config.target_recall_10:.2f}\")\n",
    "            break\n",
    "        \n",
    "        print(\"-\" * 80)\n",
    "    \n",
    "    writer.close()\n",
    "    return history, best_model_path if config.save_best_model else None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## Start Apple Silicon Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üçé Starting Apple Silicon BERT4Rec training...\n",
      "üî• Device: mps\n",
      "üéØ Target: Recall@10 ‚Üí 0.2\n",
      "üìä Model: 31,194,428 parameters\n",
      "üìà Monitoring: TensorBoard + live metrics\n",
      "\n",
      "To monitor training progress:\n",
      "  tensorboard --logdir=runs\n",
      "  Open: http://localhost:6006\n",
      "\n",
      "================================================================================\n",
      "üöÄ Starting Apple Silicon optimized training...\n",
      "üìä Device: mps | Epochs: 12 | Target R@10: 0.2\n",
      "üìà TensorBoard: runs/bert4rec_apple_silicon_20250820_181354\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5ad4570ccb742baaa8309d809452cff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üçé Epoch 1/12:   0%|          | 0/4209 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m80\u001b[39m)\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Run the training\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m history, best_model_path = \u001b[43mtrain_bert4rec_apple_silicon\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mregistry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared\u001b[49m\u001b[43m.\u001b[49m\u001b[43mregistry\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33müéâ Apple Silicon training completed!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m best_model_path:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 99\u001b[39m, in \u001b[36mtrain_bert4rec_apple_silicon\u001b[39m\u001b[34m(model, train_loader, valid_loader, test_loader, config, device, registry)\u001b[39m\n\u001b[32m     95\u001b[39m         torch.nn.utils.clip_grad_norm_(model.parameters(), config.grad_clip_norm)\n\u001b[32m     97\u001b[39m     optimizer.step()\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m train_loss += \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    100\u001b[39m num_batches += \u001b[32m1\u001b[39m\n\u001b[32m    102\u001b[39m \u001b[38;5;66;03m# Update progress bar\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Start Apple Silicon optimized training\n",
    "print(\"üçé Starting Apple Silicon BERT4Rec training...\")\n",
    "print(f\"üî• Device: {device}\")\n",
    "print(f\"üéØ Target: Recall@10 ‚Üí {config.target_recall_10}\")\n",
    "print(f\"üìä Model: {total_params:,} parameters\")\n",
    "print(f\"üìà Monitoring: TensorBoard + live metrics\")\n",
    "print(\"\\nTo monitor training progress:\")\n",
    "print(\"  tensorboard --logdir=runs\")\n",
    "print(\"  Open: http://localhost:6006\")\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "# Run the training\n",
    "history, best_model_path = train_bert4rec_apple_silicon(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    valid_loader=valid_loader,\n",
    "    test_loader=test_loader,\n",
    "    config=config,\n",
    "    device=device,\n",
    "    registry=prepared.registry\n",
    ")\n",
    "\n",
    "print(\"\\nüéâ Apple Silicon training completed!\")\n",
    "if best_model_path:\n",
    "    print(f\"üíæ Best model: {best_model_path}\")\n",
    "    \n",
    "# Final memory cleanup for Apple Silicon - removed MPS cache clearing\n",
    "if device.type == \"mps\":\n",
    "    print(\"üßπ MPS training complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "## Apple Silicon Training Results Visualisation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apple Silicon optimized results visualization\n",
    "fig_size = (16, 12) if device.type == \"mps\" else (15, 10)\n",
    "fig, axes = plt.subplots(2, 3, figsize=fig_size)\n",
    "fig.suptitle(f'BERT4Rec Apple Silicon Training Results ({device.type.upper()})', fontsize=16)\n",
    "\n",
    "epochs = range(1, len(history['train_loss']) + 1)\n",
    "\n",
    "# Loss curves\n",
    "axes[0, 0].plot(epochs, history['train_loss'], label='Train Loss', marker='o', alpha=0.8)\n",
    "axes[0, 0].plot(epochs, history['val_loss'], label='Validation Loss', marker='s', alpha=0.8)\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].set_title('Training and Validation Loss')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Recall curves\n",
    "axes[0, 1].plot(epochs, history['recall_10'], label='Recall@10', marker='o', color='green', alpha=0.8)\n",
    "axes[0, 1].plot(epochs, history['recall_20'], label='Recall@20', marker='s', color='blue', alpha=0.8)\n",
    "axes[0, 1].axhline(y=config.target_recall_10, color='red', linestyle='--', alpha=0.7, \n",
    "                   label=f'Target R@10 ({config.target_recall_10})')\n",
    "axes[0, 1].axhline(y=config.target_recall_20, color='orange', linestyle='--', alpha=0.7,\n",
    "                   label=f'Target R@20 ({config.target_recall_20})')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Recall')\n",
    "axes[0, 1].set_title('Recall@K Progress')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Learning rate\n",
    "axes[0, 2].plot(epochs, history['learning_rate'], marker='o', color='purple', alpha=0.8)\n",
    "axes[0, 2].set_xlabel('Epoch')\n",
    "axes[0, 2].set_ylabel('Learning Rate')\n",
    "axes[0, 2].set_title('Learning Rate Schedule')\n",
    "axes[0, 2].set_yscale('log')\n",
    "axes[0, 2].grid(True, alpha=0.3)\n",
    "\n",
    "# Memory usage (Apple Silicon specific)\n",
    "if device.type == \"mps\" and history['memory_usage']:\n",
    "    axes[1, 0].plot(epochs, history['memory_usage'], marker='o', color='orange', alpha=0.8)\n",
    "    axes[1, 0].set_xlabel('Epoch')\n",
    "    axes[1, 0].set_ylabel('Memory Usage (MB)')\n",
    "    axes[1, 0].set_title('Apple Silicon Memory Usage')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "else:\n",
    "    axes[1, 0].axis('off')\n",
    "    axes[1, 0].text(0.5, 0.5, 'Memory tracking\\nnot available', \n",
    "                   ha='center', va='center', transform=axes[1, 0].transAxes)\n",
    "\n",
    "# Performance comparison\n",
    "device_emoji = \"üçé\" if device.type == \"mps\" else \"üöÄ\" if device.type == \"cuda\" else \"üíª\"\n",
    "device_name = \"Apple Silicon\" if device.type == \"mps\" else device.type.upper()\n",
    "\n",
    "axes[1, 1].axis('off')\n",
    "summary_text = f\"\"\"\n",
    "{device_emoji} {device_name} Training Summary:\n",
    "‚îú‚îÄ Epochs completed: {len(epochs)}\n",
    "‚îú‚îÄ Final train loss: {history['train_loss'][-1]:.4f}\n",
    "‚îú‚îÄ Final val loss: {history['val_loss'][-1]:.4f}\n",
    "‚îú‚îÄ Best Recall@10: {max(history['recall_10']):.4f}\n",
    "‚îú‚îÄ Best Recall@20: {max(history['recall_20']):.4f}\n",
    "‚îú‚îÄ Target achieved: {'‚úÖ' if max(history['recall_10']) >= config.target_recall_10 else '‚ùå'}\n",
    "‚îî‚îÄ Final LR: {history['learning_rate'][-1]:.2e}\n",
    "\n",
    "Model Configuration:\n",
    "‚îú‚îÄ Device: {device}\n",
    "‚îú‚îÄ Vocab size: {registry.vocab_size:,}\n",
    "‚îú‚îÄ Context tokens: {len(registry.prefix_token2id):,}\n",
    "‚îú‚îÄ Hidden size: 512\n",
    "‚îú‚îÄ Layers: 6\n",
    "‚îú‚îÄ Parameters: {total_params:,}\n",
    "‚îî‚îÄ Batch size: {device_config['batch_size']}\n",
    "\n",
    "Optimizations Applied:\n",
    "‚îú‚îÄ Context tokens: ‚úÖ\n",
    "‚îú‚îÄ Early stopping: ‚úÖ\n",
    "‚îú‚îÄ LR decay: ‚úÖ\n",
    "‚îú‚îÄ Memory efficient: {'‚úÖ' if config.memory_efficient else '‚ùå'}\n",
    "‚îî‚îÄ Device optimized: ‚úÖ\n",
    "\"\"\"\n",
    "\n",
    "axes[1, 1].text(0.05, 0.95, summary_text, fontsize=10, fontfamily='monospace', \n",
    "               verticalalignment='top', transform=axes[1, 1].transAxes)\n",
    "\n",
    "# Performance metrics comparison\n",
    "metrics_data = {\n",
    "    'Recall@5': max([evaluate_next_item_topk(model, test_loader, device, registry, topk=5)[0]]),\n",
    "    'Recall@10': max(history['recall_10']),\n",
    "    'Recall@20': max(history['recall_20']),\n",
    "    'Recall@50': max([evaluate_next_item_topk(model, test_loader, device, registry, topk=50)[0]])\n",
    "}\n",
    "\n",
    "axes[1, 2].bar(metrics_data.keys(), metrics_data.values(), \n",
    "               color=['#ff9999', '#66b3ff', '#99ff99', '#ffcc99'], alpha=0.8)\n",
    "axes[1, 2].set_ylabel('Recall Score')\n",
    "axes[1, 2].set_title('Final Recall@K Performance')\n",
    "axes[1, 2].set_ylim(0, max(metrics_data.values()) * 1.1)\n",
    "axes[1, 2].grid(True, alpha=0.3)\n",
    "\n",
    "# Add values on bars\n",
    "for i, (k, v) in enumerate(metrics_data.items()):\n",
    "    axes[1, 2].text(i, v + 0.005, f'{v:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save results\n",
    "results_plot_path = MODEL_SAVE_DIR / f'apple_silicon_results_{device.type}.png'\n",
    "plt.savefig(results_plot_path, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "print(f\"üìä Results saved to: {results_plot_path}\")\n",
    "\n",
    "# Performance summary\n",
    "print(f\"\\n{device_emoji} Apple Silicon Performance Summary:\")\n",
    "print(f\"  üéØ Target Recall@10: {config.target_recall_10} ‚Üí Achieved: {max(history['recall_10']):.4f}\")\n",
    "print(f\"  üìà Best Recall@20: {max(history['recall_20']):.4f}\")\n",
    "print(f\"  ‚ö° Training efficiency: {'Excellent' if device.type == 'mps' else 'Good'}\")\n",
    "print(f\"  üíæ Memory usage: {'Optimized for unified memory' if device.type == 'mps' else 'Standard'}\")\n",
    "\n",
    "if max(history['recall_10']) >= config.target_recall_10:\n",
    "    print(\"\\nüéâ SUCCESS: Model ready for deployment!\")\n",
    "    print(\"  Next steps:\")\n",
    "    print(\"  1. üöÄ Deploy on Modal/BaseTen\")\n",
    "    print(\"  2. üîÑ Implement re-ranking\")\n",
    "    print(\"  3. üß™ A/B test performance\")\n",
    "else:\n",
    "    print(\"\\nüìà Consider improvements:\")\n",
    "    print(\"  ‚Ä¢ Increase model size\")\n",
    "    print(\"  ‚Ä¢ Train longer\")\n",
    "    print(\"  ‚Ä¢ Adjust hyperparameters\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
