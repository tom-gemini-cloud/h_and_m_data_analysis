{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# BERT4Rec Advanced Training\n",
    "\n",
    "## Enhanced training with early stopping, learning rate decay, and comprehensive monitoring\n",
    "\n",
    "This notebook implements:\n",
    "\n",
    "- 8-12 epochs with early stopping\n",
    "- Learning rate decay when validation loss plateaus\n",
    "- TensorBoard monitoring\n",
    "- Recall@10 evaluation during training\n",
    "- Target: Recall@10 ‚Üí ~0.20‚Äì0.25\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'hnm_data_analysis'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Import BERT4Rec implementation\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mhnm_data_analysis\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata_modelling\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbert4rec_modelling\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     18\u001b[39m     SequenceOptions, prepare_sequences_with_polars,\n\u001b[32m     19\u001b[39m     build_dataloaders_for_bert4rec, BERT4RecModel, TrainConfig,\n\u001b[32m     20\u001b[39m     train_bert4rec, evaluate_next_item_topk, set_all_seeds,\n\u001b[32m     21\u001b[39m     MaskingOptions\n\u001b[32m     22\u001b[39m )\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# Set paths\u001b[39;00m\n\u001b[32m     25\u001b[39m DATA_ROOT = Path(\u001b[33m'\u001b[39m\u001b[33m../../data/modelling_data\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'hnm_data_analysis'"
     ]
    }
   ],
   "source": [
    "# Core imports\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Add project root to path\n",
    "sys.path.append('../../')\n",
    "\n",
    "# Import BERT4Rec implementation\n",
    "from hnm_data_analysis.data_modelling.bert4rec_modelling import (\n",
    "    SequenceOptions, prepare_sequences_with_polars,\n",
    "    build_dataloaders_for_bert4rec, BERT4RecModel, TrainConfig,\n",
    "    train_bert4rec, evaluate_next_item_topk, set_all_seeds,\n",
    "    MaskingOptions\n",
    ")\n",
    "\n",
    "# Set paths\n",
    "DATA_ROOT = Path('../../data/modelling_data')\n",
    "MODEL_SAVE_DIR = Path('../../models/bert4rec')\n",
    "MODEL_SAVE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Enhanced Training Configuration\n",
    "\n",
    "**Context Tokens for Better Calibration:**\n",
    "\n",
    "- **[SEG] tokens**: Customer segment information helps model understand user preferences\n",
    "- **[CH] tokens**: Sales channel context (online vs store) affects purchase patterns\n",
    "- **Price-band tokens**: Price sensitivity information improves recommendation quality\n",
    "- **Expected improvement**: +0.02-0.05 boost in Recall@10 and NDCG through better calibration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced training configuration\n",
    "class AdvancedTrainConfig:\n",
    "    def __init__(self):\n",
    "        # Training parameters\n",
    "        self.n_epochs = 12\n",
    "        self.lr = 1e-4\n",
    "        self.weight_decay = 0.01\n",
    "        self.warmup_steps = 1000\n",
    "        self.grad_clip_norm = 1.0\n",
    "        \n",
    "        # Early stopping\n",
    "        self.early_stopping_patience = 3\n",
    "        self.min_delta = 0.001  # Minimum improvement to consider\n",
    "        \n",
    "        # Learning rate decay\n",
    "        self.lr_decay_patience = 2\n",
    "        self.lr_decay_factor = 0.5\n",
    "        self.min_lr = 1e-6\n",
    "        \n",
    "        # Evaluation\n",
    "        self.eval_every_n_epochs = 1\n",
    "        self.save_best_model = True\n",
    "        \n",
    "        # Target metrics\n",
    "        self.target_recall_10 = 0.20\n",
    "        self.target_recall_20 = 0.25\n",
    "\n",
    "config = AdvancedTrainConfig()\n",
    "print(f\"Training for up to {config.n_epochs} epochs with early stopping\")\n",
    "print(f\"Target Recall@10: {config.target_recall_10}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": "# Load data\nprint(\"Loading transaction data...\")\ndf = pl.read_parquet(DATA_ROOT / 'transactions_final.parquet')\n\nprint(f\"Data shape: {df.shape}\")\nprint(f\"Date range: {df['t_dat'].min()} to {df['t_dat'].max()}\")\nprint(f\"Unique customers: {df['customer_id'].n_unique():,}\")\nprint(f\"Unique articles: {df['article_id'].n_unique():,}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequence preparation with optimized settings + context tokens\n",
    "set_all_seeds(42)\n",
    "\n",
    "sequence_options = SequenceOptions(\n",
    "    max_len=50,           # Maximum sequence length \n",
    "    min_len=3,            # Minimum sequence length\n",
    "    deduplicate_exact=True,\n",
    "    treat_same_day_as_basket=True,\n",
    "    # Enable context tokens for better calibration\n",
    "    add_segment_prefix=True,     # Add [SEG] tokens based on customer segments\n",
    "    add_channel_prefix=True,     # Add [CH] tokens based on sales channel\n",
    "    add_priceband_prefix=True,   # Add price-band tokens\n",
    "    n_price_bins=10              # Number of price bands\n",
    ")\n",
    "\n",
    "print(\"Preparing sequences with context tokens...\")\n",
    "print(\"Context tokens enabled:\")\n",
    "print(f\"  ‚úì Segment prefix: {sequence_options.add_segment_prefix}\")\n",
    "print(f\"  ‚úì Channel prefix: {sequence_options.add_channel_prefix}\")\n",
    "print(f\"  ‚úì Price-band prefix: {sequence_options.add_priceband_prefix}\")\n",
    "\n",
    "# Check if required columns exist for context tokens\n",
    "required_cols = ['customer_id', 'article_id', 't_dat']\n",
    "optional_cols = {\n",
    "    'customer_segment': sequence_options.add_segment_prefix,\n",
    "    'sales_channel_id': sequence_options.add_channel_prefix\n",
    "}\n",
    "\n",
    "print(f\"\\nData columns available: {df.columns}\")\n",
    "missing_required = [col for col in required_cols if col not in df.columns]\n",
    "if missing_required:\n",
    "    print(f\"‚ùå Missing required columns: {missing_required}\")\n",
    "else:\n",
    "    print(f\"‚úÖ All required columns present\")\n",
    "\n",
    "for col, needed in optional_cols.items():\n",
    "    if needed:\n",
    "        if col in df.columns:\n",
    "            print(f\"‚úÖ {col} available for context tokens\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è  {col} not found - will skip this context token type\")\n",
    "\n",
    "# Prepare sequences (function will handle missing columns gracefully)\n",
    "prepared = prepare_sequences_with_polars(df, sequence_options)\n",
    "\n",
    "print(f\"\\nSequence preparation complete:\")\n",
    "print(f\"  Total sequences: {len(prepared.sequences):,}\")\n",
    "print(f\"  Vocabulary size: {prepared.registry.vocab_size:,}\")\n",
    "print(f\"  Prefix tokens: {len(prepared.registry.prefix_token2id):,}\")\n",
    "print(f\"  Average sequence length: {np.mean([len(seq) for seq in prepared.sequences]):.1f}\")\n",
    "print(f\"  Average prefix length: {np.mean(prepared.prefix_lengths):.1f}\")\n",
    "\n",
    "# Show some example prefix tokens\n",
    "if prepared.registry.prefix_token2id:\n",
    "    print(f\"\\nExample context tokens:\")\n",
    "    for i, (token, token_id) in enumerate(list(prepared.registry.prefix_token2id.items())[:10]):\n",
    "        print(f\"  {token_id}: {token}\")\n",
    "        if i >= 9:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## Enhanced Training Function with Monitoring\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": "def train_bert4rec_advanced(\n    model, train_loader, valid_loader, test_loader, config, device, registry\n):\n    \"\"\"\n    Enhanced training with early stopping, LR decay, and monitoring\n    \"\"\"\n    # Setup TensorBoard\n    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n    writer = SummaryWriter(f'runs/bert4rec_advanced_{timestamp}')\n    \n    # Optimizers and schedulers\n    optimizer = torch.optim.AdamW(\n        model.parameters(), \n        lr=config.lr, \n        weight_decay=config.weight_decay\n    )\n    \n    # Learning rate scheduler (reduce on plateau)\n    lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n        optimizer,\n        mode='min',\n        factor=config.lr_decay_factor,\n        patience=config.lr_decay_patience,\n        min_lr=config.min_lr\n    )\n    \n    criterion = nn.CrossEntropyLoss(ignore_index=-100)\n    \n    # Early stopping variables\n    best_val_loss = float('inf')\n    best_recall_10 = 0.0\n    patience_counter = 0\n    \n    # Training history\n    history = {\n        'train_loss': [],\n        'val_loss': [],\n        'recall_10': [],\n        'recall_20': [],\n        'learning_rate': []\n    }\n    \n    print(f\"Starting training for up to {config.n_epochs} epochs...\")\n    print(f\"TensorBoard logs: runs/bert4rec_advanced_{timestamp}\")\n    \n    for epoch in range(1, config.n_epochs + 1):\n        # Training phase\n        model.train()\n        train_loss = 0.0\n        num_batches = 0\n        \n        from tqdm.auto import tqdm\n        pbar = tqdm(train_loader, desc=f\"Epoch {epoch}/{config.n_epochs}\")\n        \n        for batch_idx, batch in enumerate(pbar):\n            input_ids = batch[\"input_ids\"].to(device)\n            attention_mask = batch[\"attention_mask\"].to(device)\n            labels = batch[\"labels\"].to(device)\n            \n            optimizer.zero_grad()\n            logits = model(input_ids, attention_mask)\n            \n            # Calculate loss\n            B, L, V = logits.size()\n            loss = criterion(logits.view(B * L, V), labels.view(B * L))\n            \n            loss.backward()\n            \n            if config.grad_clip_norm > 0:\n                torch.nn.utils.clip_grad_norm_(model.parameters(), config.grad_clip_norm)\n            \n            optimizer.step()\n            \n            train_loss += loss.item()\n            num_batches += 1\n            \n            # Update progress bar\n            pbar.set_postfix({\n                'loss': f'{loss.item():.4f}',\n                'avg_loss': f'{train_loss/num_batches:.4f}'\n            })\n            \n            # Log batch metrics to TensorBoard\n            global_step = (epoch - 1) * len(train_loader) + batch_idx\n            writer.add_scalar('Loss/Train_Batch', loss.item(), global_step)\n            writer.add_scalar('Learning_Rate', optimizer.param_groups[0]['lr'], global_step)\n        \n        avg_train_loss = train_loss / num_batches\n        \n        # Validation phase\n        model.eval()\n        val_loss = 0.0\n        with torch.no_grad():\n            for batch in tqdm(valid_loader, desc=\"Validation\", leave=False):\n                input_ids = batch[\"input_ids\"].to(device)\n                attention_mask = batch[\"attention_mask\"].to(device)\n                labels = batch[\"labels\"].to(device)\n                \n                logits = model(input_ids, attention_mask)\n                B, L, V = logits.size()\n                loss = criterion(logits.view(B * L, V), labels.view(B * L))\n                val_loss += loss.item()\n        \n        avg_val_loss = val_loss / len(valid_loader)\n        \n        # Evaluate Recall@K every epoch\n        print(f\"\\nEvaluating Recall@K...\")\n        recall_10, ndcg_10 = evaluate_next_item_topk(model, test_loader, device, registry, topk=10)\n        recall_20, ndcg_20 = evaluate_next_item_topk(model, test_loader, device, registry, topk=20)\n        \n        # Store history\n        history['train_loss'].append(avg_train_loss)\n        history['val_loss'].append(avg_val_loss)\n        history['recall_10'].append(recall_10)\n        history['recall_20'].append(recall_20)\n        history['learning_rate'].append(optimizer.param_groups[0]['lr'])\n        \n        # Log to TensorBoard\n        writer.add_scalar('Loss/Train_Epoch', avg_train_loss, epoch)\n        writer.add_scalar('Loss/Validation', avg_val_loss, epoch)\n        writer.add_scalar('Metrics/Recall@10', recall_10, epoch)\n        writer.add_scalar('Metrics/Recall@20', recall_20, epoch)\n        writer.add_scalar('Metrics/NDCG@10', ndcg_10, epoch)\n        writer.add_scalar('Metrics/NDCG@20', ndcg_20, epoch)\n        \n        # Print epoch summary\n        print(f\"\\nEpoch {epoch}/{config.n_epochs} Summary:\")\n        print(f\"  Train Loss: {avg_train_loss:.4f}\")\n        print(f\"  Val Loss:   {avg_val_loss:.4f}\")\n        print(f\"  Recall@10:  {recall_10:.4f} (Target: {config.target_recall_10:.2f})\")\n        print(f\"  Recall@20:  {recall_20:.4f} (Target: {config.target_recall_20:.2f})\")\n        print(f\"  NDCG@10:    {ndcg_10:.4f}\")\n        print(f\"  LR:         {optimizer.param_groups[0]['lr']:.2e}\")\n        \n        # Learning rate decay on plateau - track changes manually\n        old_lr = optimizer.param_groups[0]['lr']\n        lr_scheduler.step(avg_val_loss)\n        new_lr = optimizer.param_groups[0]['lr']\n        if new_lr < old_lr:\n            print(f\"  üìâ Learning rate reduced: {old_lr:.2e} ‚Üí {new_lr:.2e}\")\n        \n        # Early stopping check\n        if avg_val_loss < best_val_loss - config.min_delta:\n            best_val_loss = avg_val_loss\n            best_recall_10 = recall_10\n            patience_counter = 0\n            \n            # Save best model\n            if config.save_best_model:\n                best_model_path = MODEL_SAVE_DIR / f'bert4rec_best_{timestamp}.pt'\n                torch.save({\n                    'epoch': epoch,\n                    'model_state_dict': model.state_dict(),\n                    'optimizer_state_dict': optimizer.state_dict(),\n                    'registry': registry,\n                    'config': config,\n                    'val_loss': best_val_loss,\n                    'recall_10': best_recall_10,\n                    'history': history\n                }, best_model_path)\n                print(f\"  üíæ Saved best model (val_loss: {best_val_loss:.4f})\")\n        else:\n            patience_counter += 1\n            print(f\"  ‚è∞ Early stopping patience: {patience_counter}/{config.early_stopping_patience}\")\n        \n        # Check early stopping\n        if patience_counter >= config.early_stopping_patience:\n            print(f\"\\nüõë Early stopping at epoch {epoch}\")\n            print(f\"   Best validation loss: {best_val_loss:.4f}\")\n            print(f\"   Best Recall@10: {best_recall_10:.4f}\")\n            break\n        \n        # Check if target achieved\n        if recall_10 >= config.target_recall_10:\n            print(f\"\\nüéØ Target Recall@10 achieved: {recall_10:.4f} >= {config.target_recall_10:.2f}\")\n            break\n        \n        print(\"-\" * 80)\n    \n    writer.close()\n    \n    return history, best_model_path if config.save_best_model else None"
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## Setup Data Loaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": "# Create data loaders with time-based splits\nmasking_options = MaskingOptions(\n    mask_prob=0.8,\n    random_token_prob=0.1,\n    keep_original_prob=0.1\n)\n\nprint(\"Building data loaders...\")\ntrain_loader, valid_loader, eval_loader = build_dataloaders_for_bert4rec(\n    prepared, \n    batch_size=64,\n    masking=masking_options,\n    valid_split=0.1,\n    num_workers=4\n)\n\nprint(f\"Train batches: {len(train_loader)}\")\nprint(f\"Valid batches: {len(valid_loader)}\")\nprint(f\"Eval batches: {len(eval_loader)}\")\nprint(f\"Registry vocab size: {prepared.registry.vocab_size}\")\n\n# Use eval_loader as test_loader\ntest_loader = eval_loader"
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Initialize and Train Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": "# Debug vocabulary and token IDs before model initialization\nprint(\"üîç Debugging vocabulary and token IDs...\")\n\n# Check vocabulary info\nprint(f\"Registry vocab size: {prepared.registry.vocab_size:,}\")\nprint(f\"Article items: {len(prepared.registry.item2id):,}\")\nprint(f\"Context tokens: {len(prepared.registry.prefix_token2id):,}\")\n\n# Check token ID ranges in sequences\nall_token_ids = []\nfor seq in prepared.sequences[:100]:  # Check first 100 sequences\n    all_token_ids.extend(seq)\n\nif all_token_ids:\n    min_token_id = min(all_token_ids)\n    max_token_id = max(all_token_ids)\n    print(f\"Token ID range in data: {min_token_id} to {max_token_id}\")\n    print(f\"Model vocab size: {prepared.registry.vocab_size}\")\n    \n    if max_token_id >= prepared.registry.vocab_size:\n        print(f\"‚ùå ERROR: Max token ID ({max_token_id}) >= vocab size ({prepared.registry.vocab_size})\")\n        print(\"This will cause IndexError!\")\n    else:\n        print(f\"‚úÖ Token IDs are within vocabulary range\")\n\n# Check a sample batch from data loader\nprint(\"\\nüîç Checking sample batch from train_loader...\")\nsample_batch = next(iter(train_loader))\ninput_ids = sample_batch[\"input_ids\"]\nprint(f\"Batch input_ids shape: {input_ids.shape}\")\nprint(f\"Batch token ID range: {input_ids.min().item()} to {input_ids.max().item()}\")\n\nif input_ids.max().item() >= prepared.registry.vocab_size:\n    print(f\"‚ùå ERROR: Batch max token ID ({input_ids.max().item()}) >= vocab size ({prepared.registry.vocab_size})\")\nelse:\n    print(f\"‚úÖ Batch token IDs are within vocabulary range\")\n\n# Initialize model with larger capacity for context tokens\nmodel = BERT4RecModel(\n    vocab_size=prepared.registry.vocab_size,  # Includes items + context tokens\n    d_model=512,    # Larger model for better context understanding\n    n_layers=6,     # More layers for complex patterns\n    n_heads=8,\n    dropout=0.1,\n    max_len=50      # Match max sequence length\n)\n\nmodel.to(device)\ntotal_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\nprint(f\"\\nüìä Model initialized successfully:\")\nprint(f\"Model parameters: {total_params:,}\")\nprint(f\"Model size: ~{total_params * 4 / 1e6:.1f} MB\")\nprint(f\"Model vocab size: {model.token_emb.num_embeddings}\")\nprint(f\"Vocab breakdown:\")\nprint(f\"  Total vocab size: {prepared.registry.vocab_size:,}\")\nprint(f\"  Article items: {len(prepared.registry.item2id):,}\")\nprint(f\"  Context tokens: {len(prepared.registry.prefix_token2id):,}\")\nspecial_tokens = prepared.registry.vocab_size - len(prepared.registry.item2id) - len(prepared.registry.prefix_token2id)\nprint(f\"  Special tokens: {special_tokens:,}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": "# Start advanced training\nprint(\"üöÄ Starting advanced BERT4Rec training...\")\nprint(f\"‚ö° Device: {device}\")\nprint(f\"üìä Target Recall@10: {config.target_recall_10:.2f}\")\nprint(\"üìà TensorBoard will be available during training\")\nprint(\"\\nTo monitor in real-time, run in another terminal:\")\nprint(\"   tensorboard --logdir=runs\")\nprint(\"   Then open: http://localhost:6006\")\nprint(\"\\n\" + \"=\" * 80)\n\n# Train the model\nhistory, best_model_path = train_bert4rec_advanced(\n    model=model,\n    train_loader=train_loader,\n    valid_loader=valid_loader,\n    test_loader=test_loader,\n    config=config,\n    device=device,\n    registry=prepared.registry\n)\n\nprint(\"\\nüéâ Training completed!\")\nif best_model_path:\n    print(f\"üíæ Best model saved to: {best_model_path}\")"
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## Training Analysis and Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle('BERT4Rec Advanced Training Results', fontsize=16)\n",
    "\n",
    "epochs = range(1, len(history['train_loss']) + 1)\n",
    "\n",
    "# Loss curves\n",
    "axes[0, 0].plot(epochs, history['train_loss'], label='Train Loss', marker='o')\n",
    "axes[0, 0].plot(epochs, history['val_loss'], label='Validation Loss', marker='s')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].set_title('Training and Validation Loss')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True)\n",
    "\n",
    "# Recall curves\n",
    "axes[0, 1].plot(epochs, history['recall_10'], label='Recall@10', marker='o', color='green')\n",
    "axes[0, 1].plot(epochs, history['recall_20'], label='Recall@20', marker='s', color='blue')\n",
    "axes[0, 1].axhline(y=config.target_recall_10, color='red', linestyle='--', label=f'Target R@10 ({config.target_recall_10})')\n",
    "axes[0, 1].axhline(y=config.target_recall_20, color='orange', linestyle='--', label=f'Target R@20 ({config.target_recall_20})')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Recall')\n",
    "axes[0, 1].set_title('Recall@K Progress')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True)\n",
    "\n",
    "# Learning rate\n",
    "axes[1, 0].plot(epochs, history['learning_rate'], marker='o', color='purple')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('Learning Rate')\n",
    "axes[1, 0].set_title('Learning Rate Schedule')\n",
    "axes[1, 0].set_yscale('log')\n",
    "axes[1, 0].grid(True)\n",
    "\n",
    "# Performance summary\n",
    "axes[1, 1].axis('off')\n",
    "summary_text = f\"\"\"\n",
    "Training Summary:\n",
    "‚îú‚îÄ Epochs completed: {len(epochs)}\n",
    "‚îú‚îÄ Final train loss: {history['train_loss'][-1]:.4f}\n",
    "‚îú‚îÄ Final val loss: {history['val_loss'][-1]:.4f}\n",
    "‚îú‚îÄ Best Recall@10: {max(history['recall_10']):.4f}\n",
    "‚îú‚îÄ Best Recall@20: {max(history['recall_20']):.4f}\n",
    "‚îú‚îÄ Target R@10 achieved: {'‚úÖ' if max(history['recall_10']) >= config.target_recall_10 else '‚ùå'}\n",
    "‚îî‚îÄ Final learning rate: {history['learning_rate'][-1]:.2e}\n",
    "\n",
    "Model Configuration:\n",
    "‚îú‚îÄ Vocab size: {registry.vocab_size:,}\n",
    "‚îú‚îÄ Hidden size: 512\n",
    "‚îú‚îÄ Layers: 6\n",
    "‚îú‚îÄ Parameters: {total_params:,}\n",
    "‚îî‚îÄ Device: {device}\n",
    "\"\"\"\n",
    "\n",
    "axes[1, 1].text(0.1, 0.9, summary_text, fontsize=11, fontfamily='monospace', \n",
    "               verticalalignment='top', transform=axes[1, 1].transAxes)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig(MODEL_SAVE_DIR / 'training_results.png', dpi=300, bbox_inches='tight')\n",
    "print(f\"üìä Training plots saved to: {MODEL_SAVE_DIR / 'training_results.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## Final Model Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": "# Load best model for final evaluation\nif best_model_path and best_model_path.exists():\n    print(\"Loading best model for final evaluation...\")\n    checkpoint = torch.load(best_model_path, map_location=device)\n    \n    # Load model state\n    model.load_state_dict(checkpoint['model_state_dict'])\n    model.eval()\n    \n    print(f\"Best model from epoch {checkpoint['epoch']}:\")\n    print(f\"‚îú‚îÄ Validation loss: {checkpoint['val_loss']:.4f}\")\n    print(f\"‚îî‚îÄ Recall@10: {checkpoint['recall_10']:.4f}\")\n\n# Comprehensive evaluation on test set\nprint(\"\\nüîç Final comprehensive evaluation...\")\n\ntest_metrics = {}\nfor k in [5, 10, 20, 50]:\n    recall_k, ndcg_k = evaluate_next_item_topk(model, test_loader, device, prepared.registry, topk=k)\n    test_metrics[f'recall_{k}'] = recall_k\n    test_metrics[f'ndcg_{k}'] = ndcg_k\n    print(f\"Recall@{k:2d}: {recall_k:.4f} | NDCG@{k:2d}: {ndcg_k:.4f}\")\n\n# Check if we achieved target performance\nprint(\"\\nüéØ Target Achievement:\")\nprint(f\"Target Recall@10 ({config.target_recall_10:.2f}): {'‚úÖ ACHIEVED' if test_metrics['recall_10'] >= config.target_recall_10 else '‚ùå Not achieved'}\")\nprint(f\"Target Recall@20 ({config.target_recall_20:.2f}): {'‚úÖ ACHIEVED' if test_metrics['recall_20'] >= config.target_recall_20 else '‚ùå Not achieved'}\")\n\nif test_metrics['recall_10'] >= config.target_recall_10:\n    print(\"\\nüéâ Model is ready for re-ranking stage!\")\n    print(\"   Next steps:\")\n    print(\"   1. Deploy for inference (Modal/BaseTen)\")\n    print(\"   2. Implement re-ranking with business rules\")\n    print(\"   3. A/B test against current system\")\nelse:\n    print(\"\\nüìà Consider further improvements:\")\n    print(\"   1. Increase model size (hidden_size, num_layers)\")\n    print(\"   2. Train for more epochs\")\n    print(\"   3. Adjust sequence length or vocabulary\")\n    print(\"   4. Try different masking strategies\")"
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "## Save Final Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": "# Save comprehensive results\nimport json\nfrom datetime import datetime\n\nresults = {\n    'timestamp': datetime.now().isoformat(),\n    'config': {\n        'n_epochs': config.n_epochs,\n        'lr': config.lr,\n        'weight_decay': config.weight_decay,\n        'early_stopping_patience': config.early_stopping_patience,\n        'lr_decay_patience': config.lr_decay_patience,\n        'target_recall_10': config.target_recall_10\n    },\n    'model': {\n        'd_model': 512,\n        'n_layers': 6,\n        'vocab_size': prepared.registry.vocab_size,\n        'total_parameters': total_params\n    },\n    'training_history': history,\n    'final_metrics': test_metrics,\n    'target_achieved': test_metrics['recall_10'] >= config.target_recall_10,\n    'best_model_path': str(best_model_path) if best_model_path else None\n}\n\nresults_path = MODEL_SAVE_DIR / 'training_results.json'\nwith open(results_path, 'w') as f:\n    json.dump(results, f, indent=2)\n\nprint(f\"üìÑ Complete results saved to: {results_path}\")\nprint(f\"üìä TensorBoard logs available in: runs/\")\nprint(f\"üíæ Best model saved to: {best_model_path}\")\n\nprint(\"\\n\" + \"=\" * 80)\nprint(\"üèÅ BERT4Rec Advanced Training Complete!\")\nprint(\"=\" * 80)"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}